# Redis7高阶

# 1、Redis单线程 VS 多线程

## 1.1、面试题

`redis到底是单线程还是多线程？`

> 这种问法其实并不严谨，为啥这么说呢？
>
> Redis4之后才慢慢支持多线程，直到Redis6/7后才稳定
>
> Redis的版本很多3.x、4.x、6.x，版本不同架构也是不同的，不限定版本问题是否单线程也不太严谨
>
> 1、版本3.x，最早版本，也就是大家口口相传的Redis是单线程
>
> 2、版本4.x，严格意义来说也不是单线程，而是负责处理客户端请求的线程是单线程，但是**开始加了点多线程的东西（异步删除）**。--貌似
>
> 3、2020年5月版本的6.x后及2020年出的7.0版本后，**告别了大家印象中的单线程，用一种全新的多线程来解决问题。**--实锤

`Redis为什么要选择单线程？`

> Redis是单线程
>
> 主要是指Redis的网络IO和键值对读写是由一个线程来完成的，Redis的处理客户端的请时包括获取（Socket读）、解析、执行、内容返回（Socket写）等都由一个顺序串行的主线程序处理，这就是所谓的“单线程”。这也是Redis对外提供键值存储的主要流程。
>
> ![image-20240225204845701](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225204845701.png)
>
> 但Redis的其他功能，**比如持久化RDB、AOF、异步删除、集群数据同步等等，其实是由额外的线程执行的。Redis命令工作线程是单线程，但是，整个Redis来说，是多线程的**。 
>
> 1. 基于内存操作：Redis的所有数据都存在内存中，因此所有的运算都是内存级别的，所以它的性能比较高。
> 2. 数据结构简单：Redis的数据结构是专门设计的，而这些简单的数据结构的查找和操作的时间大部分复杂度都是O(1)，因此性能比较高。
> 3. 多路复用和非阻塞I/O：Redis使用I/O多路复用功能来监听多个Socket连接客户端，这样就可以使用一个线程连接来处理多个请求，减少线程切换带来的开销，同时避免了I/O阻塞。
> 4. 避免上下文切换：因为是单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生。



`Redis4.0之前一直采用单线程的主要原因有什么？`

> 简单来说，Redis4.0之前一直采用单线程的主要原因有以下三个：
>
> 1. 使用单线程模型使Redis的开发和维护更简单，因为单线程模型方便开发和调试。
> 2. 即使使用单线程模型也并发的处理了多客户端的请求，主要使用的是I/O多路复用和非阻塞IO。
> 3. 对于Redis系统来说，**主要的性能瓶颈是内存或者网络带宽而并非CPU**。



`既然单线程这么好，为什么逐渐又加入了多线程特性？`

> 正常情况下使用del指令可以很快的删除数据，而当被删除的key是一个非常大的对象时，例如是包含了成千上万个元素的hash集合时，那么del之灵就会造成Redis主线程卡顿。
>
> **这就是Redis3.x单线程时代最经典的故障，大Key删除的头疼问题。**
>
> 由于Redis是单线程，del bigkey
>
> 等待很久这个线程才会释放，类似加了一个synchronized锁，高并发的时候，程序会非常堵。
>
> **解决：**
>
> 1. 使用惰性删除可以有效的避免Redis卡顿的问题。
> 2. 在Redis4.0就引入了多个线程来实现数据的异步惰性删除等功能，但是其处理读写请求的仍然只有一个线程，所以仍然算是狭义上的单线程。



`Unix网络编程中的五种IO模型`

> - Blocking IO -- 阻塞IO
> - NoneBlocking -- 非阻塞IO
> - IO Multiplexing -- IO多路复用
> - Signal Driven IO -- 信号驱动IO
> - Asynchronous IO -- 异步IO



`什么是IO多路复用`

> 1. Linux世界一切接文件
> 2. IO多路复用是什么？
>    1. 一种同步的IO模型，实现**一个线程**监视**多个文件句柄，一旦某个文件句柄就绪**就能够通知对应应程序进行相应的读写操作，**没有文件句柄就绪时**就会阻塞应用程序，从而释放CPU资源
>    2. 概念：
>       - I/O：网络I/O，尤其在操作系统层面指数据在内核态和用户态之间的读写操作
>       - 多路：多个客户端连接（连接就是套接字描述符，即Socket或者Channel）
>       - 复用：复用一个或者几个线程
>       - IO多路复用：也就是说一个或一组线程处理多个TCP连接，使用单进程就能够实现同时处理多个客户端的连接，**无需创建或者维护过多的进程/线程**
> 3. 场景体验，引出Epoll
> 4. 小总结
>    - 只使用一个服务端进程可以同时处理多个套接字描述符连接



`Redis为什么这么快？`

> IO多路复用+epoll函数使用，才是Redis为什么这么快的直接原因，而不是仅仅单线程命令+Redis安装在内存中。



## 1.2、Redis7默认是否开启了多线程？

如果在实际应用中，发现Redis实例的**CPU开销不大但吞吐量却没有提升**，可以考虑使用Redis7的多线程机制，加速网络处理，进而提升实例的吞吐量。

Redis7将所有数据放在内存中，内存的响应时间长大约为100纳秒，对于小数据包，Redis服务器可以处理8W到10W的QPS，这也是Redis处理的极限了，**对于80%的公司来说，单线程的Redis已经足够使用了**。

在Redis6.0及7后，**多线程机制默认是关闭的，如果需要使用多线程功能，需要在Redis.conf中完成两个设置。

![image-20240225224329078](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225224329078.png)

![image-20240225224614883](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225224614883.png)



## 1.3、小总结

> Redis自身出道就是优秀，基于内存操作、数据结构简单、多路复用和非阻塞I/O、避免了不必要的线程上下文切换等特性，在单线程的环境下依然很快；
>
> 但对于大数据的Key删除还是卡顿厉害，因此在Redis4.0引入了多线程unlink key / flushall async等命令，主要用于Redis数据的异步删除；
>
> 而在Redis6/7中引入了I/O多线程的读写，这样就可以更加高效的处理更多的任务了，**Redis只是将I/O读写变成了多线程**，而**命令执行依旧是由主线程串行执行**，因此在多线程下操作Redis不会出现线程安全的问题了。
>
> **Redis无论是当初的单线程设计，还是如今与放出设计相背的多线程，目的只有一个：让Redis变得越来越快**。

# 2、BigKey

## 2.1、面试题

`阿里广告平台，海量数据里查询某以固定前缀的key`

`小红书，你如何生产上限值key */flushdb/flushall等危险命令以防止误删误用？`

`美团，MEMORY USAGE命令你用过吗?`

`Bigkey问题，多大算big？你如何发现？如何删除？如何解决？`

`BigKey你做过调优吗？惰性释放lazyfree了解过吗？`

`MoreKey问题，生产上redis数据有1000W记录，你如何遍历？key *可以吗？`



## 2.2、MoreKey案例

Linux Bash下执行，插入100W

```bash
for((i=1;i<=100*10000;i++)); do echo "set k$i v$i" >> /tmp/redisTest.txt;done;
```

通过Redis提供的管道 --pipe命令插入100w大批量数据

```bash
cat /tmp/redisTest.txt | redis-cli -h 127.0.0.1 -p 6399 -a zzq121700 --pipe
```

使用DBSIZE检查数据时候插入

```bash
DBSIZE
```

如果执行Keys *，Redis的时间（这次跑的算还好），在线上的Redis执行这个命令，基本就GG了

![image-20240225233619154](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225233619154.png)

<font color="red">keys * 这个执行致命的弊端，在实际环境中最好不要使用</font>

```markdown
这个指令没有offset、limit参数，是要一次性吐出所有满足条件的key，由于Redis是单线程，其所有操作都是原子的，而keys算法是遍历算法，复杂度是O(n)，如果实例中有千万级以上的key，这个指令就会导致Redis服务卡顿，所有读写Redis的其他的指令都会被延后甚至会超时报错，可能会引起缓存雪崩甚至数据库宕机。
```



**生产上限制keys * / flushdb / flushall等命令以防止误删误用？**

通过配置设置禁用这些命令，redis.conf在SECURITY这一项中

![image-20240225234832005](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225234832005.png)

![image-20240225235003742](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225235003742.png)

再次使用keys * ，就会被禁止

![image-20240225235400628](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240225235400628.png)



**不用keys *避免卡顿，那该用什么呢？**

官网：[SCAN](https://redis.io/commands/scan/)

类似mysql limit的**但不完全相同**

Scan命令用于迭代数据库中的数据库键

语法：

```bash
SCAN cursor [MATCH pattern] [COUNT count]
cursor --游标
pattrrn --匹配的模式
count --指定从数据集里返回多少个元素，默认值是10
```

特点：

1. Scan命令是一个基于游标的迭代器，每次被调用之后，都会向用户返回一个新的游标，**用户在下次迭代时需要使用这个新游标作为SCAN命令游标参数**，以此来延续之前的迭代过程。
2. Scan返回一个包含两个元素的数组
   1. 第一个元素适用于进行下一次迭代的新游标
   2. 第二个元素则是一个数组，这个数组中包含了所有被迭代的元素。**如果新游标返回零表示迭代已结束**。
3. SCAN的遍历顺序：**非常特别，他不是从低一维数组的第零位一直遍历到尾，而是采用了高位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏**。

使用：

```bash
SCAN 0 match k* count 15
```



## 2.3、BigKey案例

`多大算Big`

> 1. 参考《阿里云Redis开发规范》
>    - 【强制】：拒绝bigkey（防止网卡流量、慢查询）
>    - String类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000
>    - 反例：一个包含200玩个元素的list。
>    - 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题（例如一个200万的zset设置1个小时过期，会触发del操作，造成阻塞，而且该操作不会出现在慢查询中（latency可查））
> 2. String和二级结构
>    1. **String是value，最大512MB但是>=10KB就是bigkey**
>    2. **list、hash、set和zset，个数超过5000就是bigkey**

`大key有哪些危害？`

> 1. 内存不均匀，集群迁移困难
> 2. 超时删除，大key删除作梗
> 3. 网络流量阻塞

`如何产生？`

> - 社交类
>   - EG：粉丝列表，典型案例粉丝逐步递增
> - 汇总统计
>   - EG：某个报表，月日年经年累月的积累’

`如何发现？`

> 1. redis-cli --bigkeys
>
>    1. ```bash
>       redis-cli -h 127.0.0.1 -p 6399 -a zzq121700 --bigkeys
>       redis-cli -h 127.0.0.1 -p 6399 -a zzq121700 --bigkeys -i 0.1
>       # 每隔100条scan指令就会休眠0.1s，ops（每秒操作数，Operations Per Second）就不会剧烈抬升，但是扫描的时间会变长
>       ```
>
>    2. 好处：给出每种数据结构Top 1 bigkey，同时给出每种数据类型的键值个数+平均大小
>
>    3. 不足：想查询大于10kb的所有key，--bigkeys参数就无能为力了，**需要用到memory usage来计算每个键值的字节数**。
>
>    4. ![image-20240226151151808](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240226151151808.png)
>
> 2. MEMORY USAGE 键
>
>    1. 计算每个键值的字节数
>    2. ![image-20240226151716405](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240226151716405.png)

`如何删除？`

> 1. 参考《阿里云Redis开发规范》
>    - 【强制】：拒绝bigkey（防止网卡流量、慢查询）
>    - String类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000
>    - 反例：一个包含200玩个元素的list。
>    - 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题（例如一个200万的zset设置1个小时过期，会触发del操作，造成阻塞，而且该操作不会出现在慢查询中（latency可查））
> 2. 官网：https://redis.com.cn/commands/scan.html
> 3. 普通命令
>    1. string：一般用del，如果过于庞大用unlink
>    2. hash：
>       1. 使用hscan每次获取少量field-value，再使用hdel删除每个field
>       2. 命令：HSCAN key cursor [ MATCH pattren ] [ COUNT count ]
>    3. list：
>       1. 使用ltrim渐进式逐步删除，直到全部删除完成
>       2. 命令：LTRIM key start stop
>    4. set：
>       1. 使用sscan每次获取部分元素，再使用srem命令删除每个元素
>       2. 命令：SSCAN set 0 =》SREM set key1 key2
>    5. zset：
>       1. 使用zscan每次获取部分元素，在使用ZREMRANGEBYRANK命令删除每个元素
>       2. 命令：ZREMRANGEBYRANK salary 0 1



## 2.4、BigKey生产调优

redis.conf配置文件LAZY FREEING相关说明

![image-20240226160804428](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240226160804428.png)

1. 阻塞和非阻塞删除命令
2. 优化配置
   1. ![image-20240226161639022](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240226161639022.png)
   2. ![image-20240226161733507](K:\GitHub\notes\Redis\Redis_AD.assets\image-20240226161733507.png)





# 3、缓存双写一致性之更新策略探讨

## 3.1、面试题

`只要用缓存，就可能会涉及到redis缓存与数据库双存储双写，只要是双写，就一定会有数据一致性问题，那么你如何解决一致性问题？`

`双写一致性，你先动缓存Redis还是数据库MYSQL哪一个？为什么？`

`延时双删做过吗？会有哪些问题？`

`有这么一种情况，微服务查询redis无，mysql有，为了保证数据双写一致性回写Redis需要注意什么？双检加锁策略了解过吗？如何尽量避免缓存击穿？`

`redis和mysql双写100%会出现纰漏，做不到强一致性，如何保证最终一致性？`



## 3.2、双写一致性

**Redis中有数据**

需要和数据库中的值相同



**Redis中无数据**

数据库中的值是最新值，且准备回写Redis



**缓存按照操作来分**

1. 只读缓存
2. 读写缓存
   1. 同步直写策略
      - 写数据库后也同步写Redis缓存，缓存和数据库中的数据一致
      - 对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略
   2. 异步缓写策略
      - 正常业务运行中，MySql数据变动了，但是可以在业务上容许出现一定时间后才作用于Redis，比如仓库、物流系统
      - 异常情况出现了，不得不将失败的动作重新修补，有可能需要借助kafka或者RabbitMQ等消息中间件，实现重试重写



**双检加锁策略：**

**避免突然key失效了，打爆Mysql，做一下预防，尽量不要出现缓存击穿的情况**

多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上**使用一个互斥锁来锁住它**。

其他的线程走到这一步拿不到锁就等着，等第一个线程查到了数据，然后做缓存。

后面的线程进来发现已经有缓存了，就直接走缓存。





## 3.3、数据库和缓存一致性的集中策略

目的：达到最终的一致性

给缓存设置过期时间，定期清理缓存并回写，是保证最终一致性的解决方案。

我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要达到过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存，达到一致性，**切记，要以为MYSQL的数据库写入库为准**。



可以停机的情况：

1. 挂牌报错，凌晨升级，温馨提示，服务降级
2. 单线程，这样重量级的数据操作最好不要多线程





四种更新策略：

1. 先更新数据库，再更新缓存（ X ）

2. 先更新缓存，再更新数据库（ X ）

3. 先删除缓存，再更新数据库（ X ）

   1. **采用延时双删策略**

   2. 双删方案面试题：

      1. 这个删除该休眠多久呢？

         - 线程A sleep的时间，就需要大于线程B读取数据再写入缓存的时间

         - 这个时间怎么确定？

           1. 第一种方法：在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，自行评估自己的项目的读数据业务逻辑的耗时，以此为基础来进行估算。然后写数据的休眠的时间则在读数据业务逻辑的耗时基础上加**百毫秒**即可。

              这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

           2. 第二种方法：新启动一个后台监控程序，例如看门狗

      2. 这中同步淘汰策略，吞吐量降低怎么办？

         - 将第二次删除作为异步的。自己起一个线程，异步删除
         - 这样，写的请求就不用沉睡一端时间后了，再返回。这么做，加大吞吐量

      3. 后续看门狗WatchDog源码分析

4. 先更新数据库，再删除缓存（ ！）

   1. 异常问题
   2. 业务指导思想
   3. 解决方案
   4. 类似经典的分布式事务问题，只有一个权威答案





小总结：















# 4、Redis与MySQL数据双写一致性工程落地案例

# 5、案例落地实战BitMap/HyperLogLog/GEO

# 6、布隆过滤器BloomFilter

# 7、缓存预热 + 缓存雪崩 + 缓存击穿

# 8、手写Redis分布式锁

# 9、Redlock算法和底层源码分析

# 10、Redis的缓存过期淘汰策略

# 11、Redis经典五大类型源码及底层实现

# 12、Redis为什么快？高性能设计之epoll和IO多路复用深度解析

# 13、终章总结